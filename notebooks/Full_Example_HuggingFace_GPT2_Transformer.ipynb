{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "SiTIpPjArIyr"
   },
   "source": [
    "# Full example with the Hugging Face Transformers package\n",
    "\n",
    "This notebook shows how to train a model (GPT2) and generate music from it, using the Hugging Face Transformers package."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "gOd93yV0sGd2"
   },
   "source": [
    "## Setup Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cellView": "form",
    "id": "fX12Yquyuihc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Nov  8 22:42:22 2023       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 545.29.02              Driver Version: 545.29.02    CUDA Version: 12.3     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce RTX 2080 Ti     Off | 00000000:01:00.0 Off |                  N/A |\n",
      "| 34%   52C    P2              61W / 250W |   6600MiB / 11264MiB |      3%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA TITAN X (Pascal)        Off | 00000000:02:00.0 Off |                  N/A |\n",
      "| 23%   29C    P8               8W / 250W |      6MiB / 12288MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A      1041      G   /usr/lib/xorg/Xorg                           56MiB |\n",
      "|    0   N/A  N/A      1339      G   /usr/bin/gnome-shell                          9MiB |\n",
      "|    0   N/A  N/A     89346      C   /home/shawley/envs/dlaie/bin/python3       6530MiB |\n",
      "|    1   N/A  N/A      1041      G   /usr/lib/xorg/Xorg                            4MiB |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: miditok in /home/shawley/envs/dlaie/lib/python3.10/site-packages (2.1.7)\n",
      "Requirement already satisfied: miditoolkit in /home/shawley/envs/dlaie/lib/python3.10/site-packages (1.0.0)\n",
      "Requirement already satisfied: torch in /home/shawley/envs/dlaie/lib/python3.10/site-packages (2.1.0)\n",
      "Requirement already satisfied: torchtoolkit in /home/shawley/envs/dlaie/lib/python3.10/site-packages (0.0.4)\n",
      "Requirement already satisfied: transformers in /home/shawley/envs/dlaie/lib/python3.10/site-packages (4.35.0)\n",
      "Requirement already satisfied: accelerate in /home/shawley/envs/dlaie/lib/python3.10/site-packages (0.24.1)\n",
      "Requirement already satisfied: evaluate in /home/shawley/envs/dlaie/lib/python3.10/site-packages (0.4.1)\n",
      "Requirement already satisfied: tqdm in /home/shawley/envs/dlaie/lib/python3.10/site-packages (4.66.1)\n",
      "Requirement already satisfied: scikit-learn in /home/shawley/envs/dlaie/lib/python3.10/site-packages (1.3.2)\n",
      "Requirement already satisfied: tensorboard in /home/shawley/envs/dlaie/lib/python3.10/site-packages (2.15.1)\n",
      "Requirement already satisfied: tokenizers>=0.13.0 in /home/shawley/envs/dlaie/lib/python3.10/site-packages (from miditok) (0.14.1)\n",
      "Requirement already satisfied: scipy in /home/shawley/envs/dlaie/lib/python3.10/site-packages (from miditok) (1.11.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.16.4 in /home/shawley/envs/dlaie/lib/python3.10/site-packages (from miditok) (0.17.3)\n",
      "Requirement already satisfied: numpy<1.24,>=1.19 in /home/shawley/envs/dlaie/lib/python3.10/site-packages (from miditok) (1.23.5)\n",
      "Requirement already satisfied: matplotlib in /home/shawley/envs/dlaie/lib/python3.10/site-packages (from miditok) (3.8.1)\n",
      "Requirement already satisfied: mido>=1.1.16 in /home/shawley/envs/dlaie/lib/python3.10/site-packages (from miditoolkit) (1.3.0)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/shawley/envs/dlaie/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: jinja2 in /home/shawley/envs/dlaie/lib/python3.10/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/shawley/envs/dlaie/lib/python3.10/site-packages (from torch) (11.0.2.54)\n",
      "Requirement already satisfied: typing-extensions in /home/shawley/envs/dlaie/lib/python3.10/site-packages (from torch) (4.8.0)\n",
      "Requirement already satisfied: networkx in /home/shawley/envs/dlaie/lib/python3.10/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: filelock in /home/shawley/envs/dlaie/lib/python3.10/site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: sympy in /home/shawley/envs/dlaie/lib/python3.10/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: fsspec in /home/shawley/envs/dlaie/lib/python3.10/site-packages (from torch) (2023.10.0)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/shawley/envs/dlaie/lib/python3.10/site-packages (from torch) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/shawley/envs/dlaie/lib/python3.10/site-packages (from torch) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/shawley/envs/dlaie/lib/python3.10/site-packages (from torch) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/shawley/envs/dlaie/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/shawley/envs/dlaie/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /home/shawley/envs/dlaie/lib/python3.10/site-packages (from torch) (2.18.1)\n",
      "Requirement already satisfied: triton==2.1.0 in /home/shawley/envs/dlaie/lib/python3.10/site-packages (from torch) (2.1.0)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/shawley/envs/dlaie/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/shawley/envs/dlaie/lib/python3.10/site-packages (from torch) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/shawley/envs/dlaie/lib/python3.10/site-packages (from torch) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/shawley/envs/dlaie/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.3.52)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/shawley/envs/dlaie/lib/python3.10/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: requests in /home/shawley/envs/dlaie/lib/python3.10/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/shawley/envs/dlaie/lib/python3.10/site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/shawley/envs/dlaie/lib/python3.10/site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /home/shawley/envs/dlaie/lib/python3.10/site-packages (from transformers) (0.4.0)\n",
      "Requirement already satisfied: psutil in /home/shawley/envs/dlaie/lib/python3.10/site-packages (from accelerate) (5.9.6)\n",
      "Requirement already satisfied: datasets>=2.0.0 in /home/shawley/envs/dlaie/lib/python3.10/site-packages (from evaluate) (2.14.6)\n",
      "Requirement already satisfied: pandas in /home/shawley/envs/dlaie/lib/python3.10/site-packages (from evaluate) (2.1.2)\n",
      "Requirement already satisfied: dill in /home/shawley/envs/dlaie/lib/python3.10/site-packages (from evaluate) (0.3.7)\n",
      "Requirement already satisfied: multiprocess in /home/shawley/envs/dlaie/lib/python3.10/site-packages (from evaluate) (0.70.15)\n",
      "Requirement already satisfied: responses<0.19 in /home/shawley/envs/dlaie/lib/python3.10/site-packages (from evaluate) (0.18.0)\n",
      "Requirement already satisfied: xxhash in /home/shawley/envs/dlaie/lib/python3.10/site-packages (from evaluate) (3.4.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /home/shawley/envs/dlaie/lib/python3.10/site-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/shawley/envs/dlaie/lib/python3.10/site-packages (from scikit-learn) (3.2.0)\n",
      "Requirement already satisfied: absl-py>=0.4 in /home/shawley/envs/dlaie/lib/python3.10/site-packages (from tensorboard) (2.0.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in /home/shawley/envs/dlaie/lib/python3.10/site-packages (from tensorboard) (1.59.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/shawley/envs/dlaie/lib/python3.10/site-packages (from tensorboard) (3.0.1)\n",
      "Requirement already satisfied: protobuf<4.24,>=3.19.6 in /home/shawley/envs/dlaie/lib/python3.10/site-packages (from tensorboard) (4.23.4)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/shawley/envs/dlaie/lib/python3.10/site-packages (from tensorboard) (2.23.4)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /home/shawley/envs/dlaie/lib/python3.10/site-packages (from tensorboard) (59.6.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/shawley/envs/dlaie/lib/python3.10/site-packages (from tensorboard) (3.5.1)\n",
      "Requirement already satisfied: six>1.9 in /home/shawley/envs/dlaie/lib/python3.10/site-packages (from tensorboard) (1.16.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /home/shawley/envs/dlaie/lib/python3.10/site-packages (from tensorboard) (1.1.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home/shawley/envs/dlaie/lib/python3.10/site-packages (from tensorboard) (0.7.2)\n",
      "Requirement already satisfied: aiohttp in /home/shawley/envs/dlaie/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.8.6)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /home/shawley/envs/dlaie/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (14.0.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/shawley/envs/dlaie/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard) (5.3.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/shawley/envs/dlaie/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard) (4.9)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/shawley/envs/dlaie/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard) (0.3.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/shawley/envs/dlaie/lib/python3.10/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard) (1.3.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/shawley/envs/dlaie/lib/python3.10/site-packages (from requests->transformers) (2.0.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/shawley/envs/dlaie/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/shawley/envs/dlaie/lib/python3.10/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/shawley/envs/dlaie/lib/python3.10/site-packages (from requests->transformers) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/shawley/envs/dlaie/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard) (2.1.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/shawley/envs/dlaie/lib/python3.10/site-packages (from matplotlib->miditok) (1.4.5)\n",
      "Requirement already satisfied: pillow>=8 in /home/shawley/envs/dlaie/lib/python3.10/site-packages (from matplotlib->miditok) (10.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/shawley/envs/dlaie/lib/python3.10/site-packages (from matplotlib->miditok) (3.1.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/shawley/envs/dlaie/lib/python3.10/site-packages (from matplotlib->miditok) (1.2.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/shawley/envs/dlaie/lib/python3.10/site-packages (from matplotlib->miditok) (4.44.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/shawley/envs/dlaie/lib/python3.10/site-packages (from matplotlib->miditok) (2.8.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/shawley/envs/dlaie/lib/python3.10/site-packages (from matplotlib->miditok) (0.12.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/shawley/envs/dlaie/lib/python3.10/site-packages (from pandas->evaluate) (2023.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/shawley/envs/dlaie/lib/python3.10/site-packages (from pandas->evaluate) (2023.3.post1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/shawley/envs/dlaie/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/shawley/envs/dlaie/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/shawley/envs/dlaie/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.1.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/shawley/envs/dlaie/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/shawley/envs/dlaie/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/shawley/envs/dlaie/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/shawley/envs/dlaie/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.2)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /home/shawley/envs/dlaie/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/shawley/envs/dlaie/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard) (3.2.2)\n"
     ]
    }
   ],
   "source": [
    "#@title Install all dependencies (run only once per session)\n",
    "\n",
    "!nvidia-smi\n",
    "\n",
    "!pip -q install miditok miditoolkit torch torchtoolkit transformers accelerate evaluate tqdm scikit-learn tensorboard\n",
    "\n",
    "![ -d \"maestro-v3.0.0\" ] || { wget \"https://storage.googleapis.com/magentadata/datasets/maestro/v3.0.0/maestro-v3.0.0-midi.zip\" -O \"maestro-v3.0.0.zip\" && unzip -q \"maestro-v3.0.0.zip\" && rm 'maestro-v3.0.0.zip' && ln -s \"maestro-v3.0.0\" \"Maestro\"; }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "fX12Yquyuihc"
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from copy import deepcopy\n",
    "\n",
    "from torch import Tensor, argmax\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.cuda import is_available as cuda_available, is_bf16_supported\n",
    "from torch.backends.mps import is_available as mps_available\n",
    "from torchtoolkit.data import create_subsets\n",
    "from transformers import GPT2LMHeadModel, GPT2Config, Trainer, TrainingArguments, GenerationConfig\n",
    "from evaluate import load as load_metric\n",
    "from miditok import REMI, TokenizerConfig\n",
    "from miditok.pytorch_data import DatasetTok, DataCollator\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert MIDI files to tokens, and load them for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading token files: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 1276/1276 [00:02<00:00, 468.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Applying BPE to dataset: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 1276/1276 [00:33<00:00, 38.56it/s]\n",
      "Loading data: Maestro_tokens_bpe/2006: 100%|███████████████████████████████████████████████████████████████████████████████████| 1276/1276 [00:01<00:00, 821.79it/s]\n"
     ]
    }
   ],
   "source": [
    "# Our tokenizer's configuration\n",
    "PITCH_RANGE = (21, 109)\n",
    "BEAT_RES = {(0, 1): 8, (1, 2): 4, (2, 4): 2, (4, 8): 1}\n",
    "NB_VELOCITIES = 24\n",
    "SPECIAL_TOKENS = [\"PAD\", \"MASK\", \"BOS\", \"EOS\"]\n",
    "USE_CHORDS = False\n",
    "USE_RESTS = False\n",
    "USE_TEMPOS = True\n",
    "USE_TIME_SIGNATURE = False\n",
    "USE_PROGRAMS = False\n",
    "NB_TEMPOS = 32\n",
    "TEMPO_RANGE = (50, 200)  # (min_tempo, max_tempo)\n",
    "TOKENIZER_PARAMS = {\n",
    "    \"pitch_range\": PITCH_RANGE,\n",
    "    \"beat_res\": BEAT_RES,\n",
    "    \"nb_velocities\": NB_VELOCITIES,\n",
    "    \"special_tokens\": SPECIAL_TOKENS,\n",
    "    \"use_chords\": USE_CHORDS,\n",
    "    \"use_rests\": USE_RESTS,\n",
    "    \"use_tempos\": USE_TEMPOS,\n",
    "    \"use_time_signatures\": USE_TIME_SIGNATURE,\n",
    "    \"use_programs\": USE_PROGRAMS,\n",
    "    \"nb_tempos\": NB_TEMPOS,\n",
    "    \"tempo_range\": TEMPO_RANGE,\n",
    "}\n",
    "config = TokenizerConfig(**TOKENIZER_PARAMS)\n",
    "\n",
    "\n",
    "# Creates the tokenizer convert MIDIs to tokens\n",
    "tokenizer = REMI(config)  # REMI\n",
    " \n",
    "tokens_path = Path('Maestro_tokens_no_bpe')\n",
    "if not Path(tokens_path).exists():      # don't re-do this unless necessary, as it takes a while\n",
    "    midi_paths = list(Path('Maestro').glob('**/*.mid')) + list(Path('Maestro').glob('**/*.midi'))\n",
    "    tokenizer.tokenize_midi_dataset(midi_paths, tokens_path)  \n",
    "\n",
    "# Learn and apply BPE to data we just tokenized\n",
    "tokens_bpe_path = Path('Maestro_tokens_bpe')\n",
    "tokens_bpe_path.mkdir(exist_ok=True, parents=True)\n",
    "tokenizer.learn_bpe(\n",
    "    vocab_size=10000,\n",
    "    tokens_paths=list(tokens_path.glob(\"**/*.json\")),\n",
    "    start_from_empty_voc=False,\n",
    ")\n",
    "tokenizer.save_params(\"tokenizer_bpe.conf\")\n",
    "tokenizer.apply_bpe_to_dataset(\n",
    "    tokens_path,\n",
    "    tokens_bpe_path,\n",
    ")\n",
    "\n",
    "# Loads tokens and create data loaders for training\n",
    "tokens_paths = list(tokens_bpe_path.glob(\"**/*.json\"))\n",
    "dataset = DatasetTok(\n",
    "    tokens_paths, max_seq_len=512, min_seq_len=384, one_token_stream=False,\n",
    ")\n",
    "subset_train, subset_valid = create_subsets(dataset, [0.3])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the model\n",
    "\n",
    "We will use the [GPT2 implementation of Hugging Face](https://huggingface.co/docs/transformers/model_doc/gpt2). This \n",
    "Feel free to explore the documentation and source code to dig deeper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates model\n",
    "config = GPT2Config(\n",
    "    vocab_size=len(tokenizer),\n",
    "    n_positions=2048,\n",
    "    n_embd=512,\n",
    "    n_layer=8,\n",
    "    n_head=8,\n",
    "    n_inner=2048,\n",
    "    resid_pdrop=.1,\n",
    "    embd_pdrop=.1,\n",
    "    attn_pdrop=.1,\n",
    "    padding_token_id=tokenizer['PAD_None'],\n",
    "    bos_token_id=tokenizer['BOS_None'],\n",
    "    eos_token_id=tokenizer['EOS_None'],\n",
    ")\n",
    "model = GPT2LMHeadModel(config)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "max_steps is given, it will override any value given in num_train_epochs\n",
      "Using auto half precision backend\n",
      "Currently training with a batch size of: 16\n",
      "***** Running training *****\n",
      "  Num examples = 14,765\n",
      "  Num Epochs = 326\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 48\n",
      "  Gradient Accumulation steps = 3\n",
      "  Total optimization steps = 100,000\n",
      "  Number of trainable parameters = 31,388,672\n",
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
      "/home/shawley/envs/dlaie/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='100000' max='100000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [100000/100000 21:22:34, Epoch 325/326]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>8.237400</td>\n",
       "      <td>8.223081</td>\n",
       "      <td>0.049883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>7.649700</td>\n",
       "      <td>7.635656</td>\n",
       "      <td>0.040801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>6.929200</td>\n",
       "      <td>6.872255</td>\n",
       "      <td>0.000421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>6.136600</td>\n",
       "      <td>6.079532</td>\n",
       "      <td>0.000118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>5.744400</td>\n",
       "      <td>5.688006</td>\n",
       "      <td>0.000207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>5.471800</td>\n",
       "      <td>5.418881</td>\n",
       "      <td>0.000154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>5.274900</td>\n",
       "      <td>5.195198</td>\n",
       "      <td>0.000123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>5.099300</td>\n",
       "      <td>5.015362</td>\n",
       "      <td>0.000151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>4.934500</td>\n",
       "      <td>4.856715</td>\n",
       "      <td>0.000202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>4.798900</td>\n",
       "      <td>4.707597</td>\n",
       "      <td>0.000363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>4.649200</td>\n",
       "      <td>4.572302</td>\n",
       "      <td>0.000609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>4.533300</td>\n",
       "      <td>4.462327</td>\n",
       "      <td>0.000734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>4.391600</td>\n",
       "      <td>4.355690</td>\n",
       "      <td>0.000606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>4.299400</td>\n",
       "      <td>4.257274</td>\n",
       "      <td>0.000841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>4.199200</td>\n",
       "      <td>4.163526</td>\n",
       "      <td>0.000645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>4.071300</td>\n",
       "      <td>4.082545</td>\n",
       "      <td>0.000589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17000</td>\n",
       "      <td>3.981800</td>\n",
       "      <td>4.017602</td>\n",
       "      <td>0.000398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>3.890100</td>\n",
       "      <td>3.964433</td>\n",
       "      <td>0.000878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19000</td>\n",
       "      <td>3.847000</td>\n",
       "      <td>3.913148</td>\n",
       "      <td>0.000572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>3.779800</td>\n",
       "      <td>3.880586</td>\n",
       "      <td>0.000339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21000</td>\n",
       "      <td>3.647400</td>\n",
       "      <td>3.849355</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22000</td>\n",
       "      <td>3.600500</td>\n",
       "      <td>3.831371</td>\n",
       "      <td>0.000265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23000</td>\n",
       "      <td>3.525300</td>\n",
       "      <td>3.808342</td>\n",
       "      <td>0.000249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24000</td>\n",
       "      <td>3.467900</td>\n",
       "      <td>3.795601</td>\n",
       "      <td>0.000134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25000</td>\n",
       "      <td>3.336800</td>\n",
       "      <td>3.799326</td>\n",
       "      <td>0.000052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26000</td>\n",
       "      <td>3.329100</td>\n",
       "      <td>3.798223</td>\n",
       "      <td>0.000060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27000</td>\n",
       "      <td>3.277700</td>\n",
       "      <td>3.793502</td>\n",
       "      <td>0.000062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28000</td>\n",
       "      <td>3.197300</td>\n",
       "      <td>3.809675</td>\n",
       "      <td>0.000056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29000</td>\n",
       "      <td>3.093000</td>\n",
       "      <td>3.820548</td>\n",
       "      <td>0.000067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30000</td>\n",
       "      <td>3.088700</td>\n",
       "      <td>3.831444</td>\n",
       "      <td>0.000029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31000</td>\n",
       "      <td>3.025400</td>\n",
       "      <td>3.846188</td>\n",
       "      <td>0.000032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32000</td>\n",
       "      <td>2.976600</td>\n",
       "      <td>3.869769</td>\n",
       "      <td>0.000034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33000</td>\n",
       "      <td>2.850900</td>\n",
       "      <td>3.901527</td>\n",
       "      <td>0.000060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34000</td>\n",
       "      <td>2.829800</td>\n",
       "      <td>3.915766</td>\n",
       "      <td>0.000109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35000</td>\n",
       "      <td>2.821800</td>\n",
       "      <td>3.940218</td>\n",
       "      <td>0.000032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36000</td>\n",
       "      <td>2.805000</td>\n",
       "      <td>3.965493</td>\n",
       "      <td>0.000041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37000</td>\n",
       "      <td>2.699400</td>\n",
       "      <td>3.997025</td>\n",
       "      <td>0.000064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38000</td>\n",
       "      <td>2.672900</td>\n",
       "      <td>4.023076</td>\n",
       "      <td>0.000043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39000</td>\n",
       "      <td>2.668600</td>\n",
       "      <td>4.035970</td>\n",
       "      <td>0.000046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40000</td>\n",
       "      <td>2.616400</td>\n",
       "      <td>4.070279</td>\n",
       "      <td>0.000057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41000</td>\n",
       "      <td>2.528300</td>\n",
       "      <td>4.106872</td>\n",
       "      <td>0.000041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42000</td>\n",
       "      <td>2.514300</td>\n",
       "      <td>4.129455</td>\n",
       "      <td>0.000052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43000</td>\n",
       "      <td>2.530900</td>\n",
       "      <td>4.153181</td>\n",
       "      <td>0.000060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44000</td>\n",
       "      <td>2.468500</td>\n",
       "      <td>4.172795</td>\n",
       "      <td>0.000030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45000</td>\n",
       "      <td>2.374000</td>\n",
       "      <td>4.201818</td>\n",
       "      <td>0.000060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46000</td>\n",
       "      <td>2.438700</td>\n",
       "      <td>4.233352</td>\n",
       "      <td>0.000077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47000</td>\n",
       "      <td>2.405800</td>\n",
       "      <td>4.243671</td>\n",
       "      <td>0.000044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48000</td>\n",
       "      <td>2.406600</td>\n",
       "      <td>4.270859</td>\n",
       "      <td>0.000059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49000</td>\n",
       "      <td>2.279100</td>\n",
       "      <td>4.303747</td>\n",
       "      <td>0.000090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50000</td>\n",
       "      <td>2.317500</td>\n",
       "      <td>4.317335</td>\n",
       "      <td>0.000081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51000</td>\n",
       "      <td>2.304300</td>\n",
       "      <td>4.335645</td>\n",
       "      <td>0.000067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52000</td>\n",
       "      <td>2.278000</td>\n",
       "      <td>4.360464</td>\n",
       "      <td>0.000071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53000</td>\n",
       "      <td>2.198500</td>\n",
       "      <td>4.389852</td>\n",
       "      <td>0.000091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54000</td>\n",
       "      <td>2.220400</td>\n",
       "      <td>4.402920</td>\n",
       "      <td>0.000093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55000</td>\n",
       "      <td>2.233500</td>\n",
       "      <td>4.419459</td>\n",
       "      <td>0.000117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56000</td>\n",
       "      <td>2.185900</td>\n",
       "      <td>4.447378</td>\n",
       "      <td>0.000062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57000</td>\n",
       "      <td>2.143400</td>\n",
       "      <td>4.468174</td>\n",
       "      <td>0.000088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58000</td>\n",
       "      <td>2.138200</td>\n",
       "      <td>4.487131</td>\n",
       "      <td>0.000091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59000</td>\n",
       "      <td>2.158400</td>\n",
       "      <td>4.496998</td>\n",
       "      <td>0.000071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60000</td>\n",
       "      <td>2.127500</td>\n",
       "      <td>4.517654</td>\n",
       "      <td>0.000080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61000</td>\n",
       "      <td>2.066100</td>\n",
       "      <td>4.536713</td>\n",
       "      <td>0.000081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62000</td>\n",
       "      <td>2.083400</td>\n",
       "      <td>4.552618</td>\n",
       "      <td>0.000075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63000</td>\n",
       "      <td>2.107700</td>\n",
       "      <td>4.573402</td>\n",
       "      <td>0.000062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64000</td>\n",
       "      <td>2.062700</td>\n",
       "      <td>4.579279</td>\n",
       "      <td>0.000067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65000</td>\n",
       "      <td>2.006000</td>\n",
       "      <td>4.604830</td>\n",
       "      <td>0.000070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66000</td>\n",
       "      <td>2.012800</td>\n",
       "      <td>4.618980</td>\n",
       "      <td>0.000090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67000</td>\n",
       "      <td>2.015400</td>\n",
       "      <td>4.624732</td>\n",
       "      <td>0.000071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68000</td>\n",
       "      <td>1.995100</td>\n",
       "      <td>4.644495</td>\n",
       "      <td>0.000075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69000</td>\n",
       "      <td>1.951800</td>\n",
       "      <td>4.661736</td>\n",
       "      <td>0.000086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70000</td>\n",
       "      <td>1.960400</td>\n",
       "      <td>4.675661</td>\n",
       "      <td>0.000061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71000</td>\n",
       "      <td>1.951100</td>\n",
       "      <td>4.678593</td>\n",
       "      <td>0.000089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72000</td>\n",
       "      <td>1.941800</td>\n",
       "      <td>4.698834</td>\n",
       "      <td>0.000071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73000</td>\n",
       "      <td>1.905300</td>\n",
       "      <td>4.716222</td>\n",
       "      <td>0.000063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74000</td>\n",
       "      <td>1.910700</td>\n",
       "      <td>4.723145</td>\n",
       "      <td>0.000071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75000</td>\n",
       "      <td>1.922200</td>\n",
       "      <td>4.737775</td>\n",
       "      <td>0.000063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76000</td>\n",
       "      <td>1.909100</td>\n",
       "      <td>4.743176</td>\n",
       "      <td>0.000071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77000</td>\n",
       "      <td>1.872400</td>\n",
       "      <td>4.753175</td>\n",
       "      <td>0.000074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78000</td>\n",
       "      <td>1.878500</td>\n",
       "      <td>4.762307</td>\n",
       "      <td>0.000066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79000</td>\n",
       "      <td>1.873100</td>\n",
       "      <td>4.767702</td>\n",
       "      <td>0.000069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80000</td>\n",
       "      <td>1.890600</td>\n",
       "      <td>4.780031</td>\n",
       "      <td>0.000070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>81000</td>\n",
       "      <td>1.851800</td>\n",
       "      <td>4.790033</td>\n",
       "      <td>0.000069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82000</td>\n",
       "      <td>1.861600</td>\n",
       "      <td>4.793922</td>\n",
       "      <td>0.000068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>83000</td>\n",
       "      <td>1.846900</td>\n",
       "      <td>4.800009</td>\n",
       "      <td>0.000067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>84000</td>\n",
       "      <td>1.834500</td>\n",
       "      <td>4.809004</td>\n",
       "      <td>0.000063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85000</td>\n",
       "      <td>1.821700</td>\n",
       "      <td>4.816483</td>\n",
       "      <td>0.000071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>86000</td>\n",
       "      <td>1.825100</td>\n",
       "      <td>4.818337</td>\n",
       "      <td>0.000070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>87000</td>\n",
       "      <td>1.823700</td>\n",
       "      <td>4.822847</td>\n",
       "      <td>0.000069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>88000</td>\n",
       "      <td>1.820900</td>\n",
       "      <td>4.826905</td>\n",
       "      <td>0.000071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>89000</td>\n",
       "      <td>1.796500</td>\n",
       "      <td>4.831120</td>\n",
       "      <td>0.000067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90000</td>\n",
       "      <td>1.810300</td>\n",
       "      <td>4.833596</td>\n",
       "      <td>0.000066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>91000</td>\n",
       "      <td>1.822000</td>\n",
       "      <td>4.837118</td>\n",
       "      <td>0.000073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>92000</td>\n",
       "      <td>1.797000</td>\n",
       "      <td>4.838106</td>\n",
       "      <td>0.000069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>93000</td>\n",
       "      <td>1.786100</td>\n",
       "      <td>4.839397</td>\n",
       "      <td>0.000073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>94000</td>\n",
       "      <td>1.796400</td>\n",
       "      <td>4.842553</td>\n",
       "      <td>0.000071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95000</td>\n",
       "      <td>1.781500</td>\n",
       "      <td>4.842718</td>\n",
       "      <td>0.000073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96000</td>\n",
       "      <td>1.782800</td>\n",
       "      <td>4.843595</td>\n",
       "      <td>0.000072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>97000</td>\n",
       "      <td>1.776200</td>\n",
       "      <td>4.843851</td>\n",
       "      <td>0.000073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98000</td>\n",
       "      <td>1.782100</td>\n",
       "      <td>4.843926</td>\n",
       "      <td>0.000073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99000</td>\n",
       "      <td>1.782000</td>\n",
       "      <td>4.844330</td>\n",
       "      <td>0.000073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100000</td>\n",
       "      <td>1.770300</td>\n",
       "      <td>4.844082</td>\n",
       "      <td>0.000074</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 6327\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to runs/checkpoint-1000\n",
      "Configuration saved in runs/checkpoint-1000/config.json\n",
      "Configuration saved in runs/checkpoint-1000/generation_config.json\n",
      "Model weights saved in runs/checkpoint-1000/pytorch_model.bin\n",
      "/home/shawley/envs/dlaie/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 6327\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to runs/checkpoint-2000\n",
      "Configuration saved in runs/checkpoint-2000/config.json\n",
      "Configuration saved in runs/checkpoint-2000/generation_config.json\n",
      "Model weights saved in runs/checkpoint-2000/pytorch_model.bin\n",
      "/home/shawley/envs/dlaie/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 6327\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to runs/checkpoint-3000\n",
      "Configuration saved in runs/checkpoint-3000/config.json\n",
      "Configuration saved in runs/checkpoint-3000/generation_config.json\n",
      "Model weights saved in runs/checkpoint-3000/pytorch_model.bin\n",
      "/home/shawley/envs/dlaie/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 6327\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to runs/checkpoint-4000\n",
      "Configuration saved in runs/checkpoint-4000/config.json\n",
      "Configuration saved in runs/checkpoint-4000/generation_config.json\n",
      "Model weights saved in runs/checkpoint-4000/pytorch_model.bin\n",
      "/home/shawley/envs/dlaie/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 6327\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to runs/checkpoint-5000\n",
      "Configuration saved in runs/checkpoint-5000/config.json\n",
      "Configuration saved in runs/checkpoint-5000/generation_config.json\n",
      "Model weights saved in runs/checkpoint-5000/pytorch_model.bin\n",
      "/home/shawley/envs/dlaie/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 6327\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to runs/checkpoint-6000\n",
      "Configuration saved in runs/checkpoint-6000/config.json\n",
      "Configuration saved in runs/checkpoint-6000/generation_config.json\n",
      "Model weights saved in runs/checkpoint-6000/pytorch_model.bin\n",
      "Deleting older checkpoint [runs/checkpoint-1000] due to args.save_total_limit\n",
      "/home/shawley/envs/dlaie/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 6327\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to runs/checkpoint-7000\n",
      "Configuration saved in runs/checkpoint-7000/config.json\n",
      "Configuration saved in runs/checkpoint-7000/generation_config.json\n",
      "Model weights saved in runs/checkpoint-7000/pytorch_model.bin\n",
      "Deleting older checkpoint [runs/checkpoint-2000] due to args.save_total_limit\n",
      "/home/shawley/envs/dlaie/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 6327\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to runs/checkpoint-8000\n",
      "Configuration saved in runs/checkpoint-8000/config.json\n",
      "Configuration saved in runs/checkpoint-8000/generation_config.json\n",
      "Model weights saved in runs/checkpoint-8000/pytorch_model.bin\n",
      "Deleting older checkpoint [runs/checkpoint-3000] due to args.save_total_limit\n",
      "/home/shawley/envs/dlaie/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 6327\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to runs/checkpoint-9000\n",
      "Configuration saved in runs/checkpoint-9000/config.json\n",
      "Configuration saved in runs/checkpoint-9000/generation_config.json\n",
      "Model weights saved in runs/checkpoint-9000/pytorch_model.bin\n",
      "Deleting older checkpoint [runs/checkpoint-4000] due to args.save_total_limit\n",
      "/home/shawley/envs/dlaie/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 6327\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to runs/checkpoint-10000\n",
      "Configuration saved in runs/checkpoint-10000/config.json\n",
      "Configuration saved in runs/checkpoint-10000/generation_config.json\n",
      "Model weights saved in runs/checkpoint-10000/pytorch_model.bin\n",
      "Deleting older checkpoint [runs/checkpoint-5000] due to args.save_total_limit\n",
      "/home/shawley/envs/dlaie/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 6327\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to runs/checkpoint-11000\n",
      "Configuration saved in runs/checkpoint-11000/config.json\n",
      "Configuration saved in runs/checkpoint-11000/generation_config.json\n",
      "Model weights saved in runs/checkpoint-11000/pytorch_model.bin\n",
      "Deleting older checkpoint [runs/checkpoint-6000] due to args.save_total_limit\n",
      "/home/shawley/envs/dlaie/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 6327\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to runs/checkpoint-12000\n",
      "Configuration saved in runs/checkpoint-12000/config.json\n",
      "Configuration saved in runs/checkpoint-12000/generation_config.json\n",
      "Model weights saved in runs/checkpoint-12000/pytorch_model.bin\n",
      "Deleting older checkpoint [runs/checkpoint-7000] due to args.save_total_limit\n",
      "/home/shawley/envs/dlaie/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 6327\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to runs/checkpoint-13000\n",
      "Configuration saved in runs/checkpoint-13000/config.json\n",
      "Configuration saved in runs/checkpoint-13000/generation_config.json\n",
      "Model weights saved in runs/checkpoint-13000/pytorch_model.bin\n",
      "Deleting older checkpoint [runs/checkpoint-8000] due to args.save_total_limit\n",
      "/home/shawley/envs/dlaie/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 6327\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to runs/checkpoint-14000\n",
      "Configuration saved in runs/checkpoint-14000/config.json\n",
      "Configuration saved in runs/checkpoint-14000/generation_config.json\n",
      "Model weights saved in runs/checkpoint-14000/pytorch_model.bin\n",
      "Deleting older checkpoint [runs/checkpoint-9000] due to args.save_total_limit\n",
      "/home/shawley/envs/dlaie/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 6327\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to runs/checkpoint-15000\n",
      "Configuration saved in runs/checkpoint-15000/config.json\n",
      "Configuration saved in runs/checkpoint-15000/generation_config.json\n",
      "Model weights saved in runs/checkpoint-15000/pytorch_model.bin\n",
      "Deleting older checkpoint [runs/checkpoint-10000] due to args.save_total_limit\n",
      "/home/shawley/envs/dlaie/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 6327\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to runs/checkpoint-16000\n",
      "Configuration saved in runs/checkpoint-16000/config.json\n",
      "Configuration saved in runs/checkpoint-16000/generation_config.json\n",
      "Model weights saved in runs/checkpoint-16000/pytorch_model.bin\n",
      "Deleting older checkpoint [runs/checkpoint-11000] due to args.save_total_limit\n",
      "/home/shawley/envs/dlaie/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 6327\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to runs/checkpoint-17000\n",
      "Configuration saved in runs/checkpoint-17000/config.json\n",
      "Configuration saved in runs/checkpoint-17000/generation_config.json\n",
      "Model weights saved in runs/checkpoint-17000/pytorch_model.bin\n",
      "Deleting older checkpoint [runs/checkpoint-12000] due to args.save_total_limit\n",
      "/home/shawley/envs/dlaie/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 6327\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to runs/checkpoint-18000\n",
      "Configuration saved in runs/checkpoint-18000/config.json\n",
      "Configuration saved in runs/checkpoint-18000/generation_config.json\n",
      "Model weights saved in runs/checkpoint-18000/pytorch_model.bin\n",
      "Deleting older checkpoint [runs/checkpoint-13000] due to args.save_total_limit\n",
      "/home/shawley/envs/dlaie/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 6327\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to runs/checkpoint-19000\n",
      "Configuration saved in runs/checkpoint-19000/config.json\n",
      "Configuration saved in runs/checkpoint-19000/generation_config.json\n",
      "Model weights saved in runs/checkpoint-19000/pytorch_model.bin\n",
      "Deleting older checkpoint [runs/checkpoint-14000] due to args.save_total_limit\n",
      "/home/shawley/envs/dlaie/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 6327\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to runs/checkpoint-20000\n",
      "Configuration saved in runs/checkpoint-20000/config.json\n",
      "Configuration saved in runs/checkpoint-20000/generation_config.json\n",
      "Model weights saved in runs/checkpoint-20000/pytorch_model.bin\n",
      "Deleting older checkpoint [runs/checkpoint-15000] due to args.save_total_limit\n",
      "/home/shawley/envs/dlaie/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 6327\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to runs/checkpoint-21000\n",
      "Configuration saved in runs/checkpoint-21000/config.json\n",
      "Configuration saved in runs/checkpoint-21000/generation_config.json\n",
      "Model weights saved in runs/checkpoint-21000/pytorch_model.bin\n",
      "Deleting older checkpoint [runs/checkpoint-16000] due to args.save_total_limit\n",
      "/home/shawley/envs/dlaie/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 6327\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to runs/checkpoint-22000\n",
      "Configuration saved in runs/checkpoint-22000/config.json\n",
      "Configuration saved in runs/checkpoint-22000/generation_config.json\n",
      "Model weights saved in runs/checkpoint-22000/pytorch_model.bin\n",
      "Deleting older checkpoint [runs/checkpoint-17000] due to args.save_total_limit\n",
      "/home/shawley/envs/dlaie/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 6327\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to runs/checkpoint-23000\n",
      "Configuration saved in runs/checkpoint-23000/config.json\n",
      "Configuration saved in runs/checkpoint-23000/generation_config.json\n",
      "Model weights saved in runs/checkpoint-23000/pytorch_model.bin\n",
      "Deleting older checkpoint [runs/checkpoint-18000] due to args.save_total_limit\n",
      "/home/shawley/envs/dlaie/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 6327\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to runs/checkpoint-24000\n",
      "Configuration saved in runs/checkpoint-24000/config.json\n",
      "Configuration saved in runs/checkpoint-24000/generation_config.json\n",
      "Model weights saved in runs/checkpoint-24000/pytorch_model.bin\n",
      "Deleting older checkpoint [runs/checkpoint-19000] due to args.save_total_limit\n",
      "/home/shawley/envs/dlaie/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 6327\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to runs/checkpoint-25000\n",
      "Configuration saved in runs/checkpoint-25000/config.json\n",
      "Configuration saved in runs/checkpoint-25000/generation_config.json\n",
      "Model weights saved in runs/checkpoint-25000/pytorch_model.bin\n",
      "Deleting older checkpoint [runs/checkpoint-20000] due to args.save_total_limit\n",
      "/home/shawley/envs/dlaie/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 6327\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to runs/checkpoint-26000\n",
      "Configuration saved in runs/checkpoint-26000/config.json\n",
      "Configuration saved in runs/checkpoint-26000/generation_config.json\n",
      "Model weights saved in runs/checkpoint-26000/pytorch_model.bin\n",
      "Deleting older checkpoint [runs/checkpoint-21000] due to args.save_total_limit\n",
      "/home/shawley/envs/dlaie/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 6327\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to runs/checkpoint-27000\n",
      "Configuration saved in runs/checkpoint-27000/config.json\n",
      "Configuration saved in runs/checkpoint-27000/generation_config.json\n",
      "Model weights saved in runs/checkpoint-27000/pytorch_model.bin\n",
      "Deleting older checkpoint [runs/checkpoint-22000] due to args.save_total_limit\n",
      "/home/shawley/envs/dlaie/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 6327\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to runs/checkpoint-28000\n",
      "Configuration saved in runs/checkpoint-28000/config.json\n",
      "Configuration saved in runs/checkpoint-28000/generation_config.json\n",
      "Model weights saved in runs/checkpoint-28000/pytorch_model.bin\n",
      "Deleting older checkpoint [runs/checkpoint-23000] due to args.save_total_limit\n",
      "/home/shawley/envs/dlaie/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 6327\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to runs/checkpoint-29000\n",
      "Configuration saved in runs/checkpoint-29000/config.json\n",
      "Configuration saved in runs/checkpoint-29000/generation_config.json\n",
      "Model weights saved in runs/checkpoint-29000/pytorch_model.bin\n",
      "Deleting older checkpoint [runs/checkpoint-24000] due to args.save_total_limit\n",
      "/home/shawley/envs/dlaie/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 6327\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to runs/checkpoint-30000\n",
      "Configuration saved in runs/checkpoint-30000/config.json\n",
      "Configuration saved in runs/checkpoint-30000/generation_config.json\n",
      "Model weights saved in runs/checkpoint-30000/pytorch_model.bin\n",
      "Deleting older checkpoint [runs/checkpoint-25000] due to args.save_total_limit\n",
      "/home/shawley/envs/dlaie/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 6327\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to runs/checkpoint-31000\n",
      "Configuration saved in runs/checkpoint-31000/config.json\n",
      "Configuration saved in runs/checkpoint-31000/generation_config.json\n",
      "Model weights saved in runs/checkpoint-31000/pytorch_model.bin\n",
      "Deleting older checkpoint [runs/checkpoint-26000] due to args.save_total_limit\n",
      "/home/shawley/envs/dlaie/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 6327\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to runs/checkpoint-32000\n",
      "Configuration saved in runs/checkpoint-32000/config.json\n",
      "Configuration saved in runs/checkpoint-32000/generation_config.json\n",
      "Model weights saved in runs/checkpoint-32000/pytorch_model.bin\n",
      "Deleting older checkpoint [runs/checkpoint-28000] due to args.save_total_limit\n",
      "/home/shawley/envs/dlaie/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 6327\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to runs/checkpoint-33000\n",
      "Configuration saved in runs/checkpoint-33000/config.json\n",
      "Configuration saved in runs/checkpoint-33000/generation_config.json\n",
      "Model weights saved in runs/checkpoint-33000/pytorch_model.bin\n",
      "Deleting older checkpoint [runs/checkpoint-29000] due to args.save_total_limit\n",
      "/home/shawley/envs/dlaie/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 6327\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to runs/checkpoint-34000\n",
      "Configuration saved in runs/checkpoint-34000/config.json\n",
      "Configuration saved in runs/checkpoint-34000/generation_config.json\n",
      "Model weights saved in runs/checkpoint-34000/pytorch_model.bin\n",
      "Deleting older checkpoint [runs/checkpoint-30000] due to args.save_total_limit\n",
      "/home/shawley/envs/dlaie/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 6327\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to runs/checkpoint-35000\n",
      "Configuration saved in runs/checkpoint-35000/config.json\n",
      "Configuration saved in runs/checkpoint-35000/generation_config.json\n",
      "Model weights saved in runs/checkpoint-35000/pytorch_model.bin\n",
      "Deleting older checkpoint [runs/checkpoint-31000] due to args.save_total_limit\n",
      "/home/shawley/envs/dlaie/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 6327\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to runs/checkpoint-36000\n",
      "Configuration saved in runs/checkpoint-36000/config.json\n",
      "Configuration saved in runs/checkpoint-36000/generation_config.json\n",
      "Model weights saved in runs/checkpoint-36000/pytorch_model.bin\n",
      "Deleting older checkpoint [runs/checkpoint-32000] due to args.save_total_limit\n",
      "/home/shawley/envs/dlaie/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 6327\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to runs/checkpoint-50000\n",
      "Configuration saved in runs/checkpoint-50000/config.json\n",
      "Configuration saved in runs/checkpoint-50000/generation_config.json\n",
      "Model weights saved in runs/checkpoint-50000/pytorch_model.bin\n",
      "Deleting older checkpoint [runs/checkpoint-46000] due to args.save_total_limit\n",
      "/home/shawley/envs/dlaie/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 6327\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to runs/checkpoint-51000\n",
      "Configuration saved in runs/checkpoint-51000/config.json\n",
      "Configuration saved in runs/checkpoint-51000/generation_config.json\n",
      "Model weights saved in runs/checkpoint-51000/pytorch_model.bin\n",
      "Deleting older checkpoint [runs/checkpoint-47000] due to args.save_total_limit\n",
      "/home/shawley/envs/dlaie/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 6327\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to runs/checkpoint-52000\n",
      "Configuration saved in runs/checkpoint-52000/config.json\n",
      "Configuration saved in runs/checkpoint-52000/generation_config.json\n",
      "Model weights saved in runs/checkpoint-52000/pytorch_model.bin\n",
      "Deleting older checkpoint [runs/checkpoint-48000] due to args.save_total_limit\n",
      "/home/shawley/envs/dlaie/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 6327\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to runs/checkpoint-53000\n",
      "Configuration saved in runs/checkpoint-53000/config.json\n",
      "Configuration saved in runs/checkpoint-53000/generation_config.json\n",
      "Model weights saved in runs/checkpoint-53000/pytorch_model.bin\n",
      "Deleting older checkpoint [runs/checkpoint-49000] due to args.save_total_limit\n",
      "/home/shawley/envs/dlaie/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 6327\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to runs/checkpoint-54000\n",
      "Configuration saved in runs/checkpoint-54000/config.json\n",
      "Configuration saved in runs/checkpoint-54000/generation_config.json\n",
      "Model weights saved in runs/checkpoint-54000/pytorch_model.bin\n",
      "Deleting older checkpoint [runs/checkpoint-50000] due to args.save_total_limit\n",
      "/home/shawley/envs/dlaie/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 6327\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to runs/checkpoint-55000\n",
      "Configuration saved in runs/checkpoint-55000/config.json\n",
      "Configuration saved in runs/checkpoint-55000/generation_config.json\n",
      "Model weights saved in runs/checkpoint-55000/pytorch_model.bin\n",
      "Deleting older checkpoint [runs/checkpoint-51000] due to args.save_total_limit\n",
      "/home/shawley/envs/dlaie/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 6327\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to runs/checkpoint-56000\n",
      "Configuration saved in runs/checkpoint-56000/config.json\n",
      "Configuration saved in runs/checkpoint-56000/generation_config.json\n",
      "Model weights saved in runs/checkpoint-56000/pytorch_model.bin\n",
      "Deleting older checkpoint [runs/checkpoint-52000] due to args.save_total_limit\n",
      "/home/shawley/envs/dlaie/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 6327\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to runs/checkpoint-57000\n",
      "Configuration saved in runs/checkpoint-57000/config.json\n",
      "Configuration saved in runs/checkpoint-57000/generation_config.json\n",
      "Model weights saved in runs/checkpoint-57000/pytorch_model.bin\n",
      "Deleting older checkpoint [runs/checkpoint-53000] due to args.save_total_limit\n",
      "/home/shawley/envs/dlaie/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 6327\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to runs/checkpoint-58000\n",
      "Configuration saved in runs/checkpoint-58000/config.json\n",
      "Configuration saved in runs/checkpoint-58000/generation_config.json\n",
      "Model weights saved in runs/checkpoint-58000/pytorch_model.bin\n",
      "Deleting older checkpoint [runs/checkpoint-54000] due to args.save_total_limit\n",
      "/home/shawley/envs/dlaie/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 6327\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to runs/checkpoint-59000\n",
      "Configuration saved in runs/checkpoint-59000/config.json\n",
      "Configuration saved in runs/checkpoint-59000/generation_config.json\n",
      "Model weights saved in runs/checkpoint-59000/pytorch_model.bin\n",
      "Deleting older checkpoint [runs/checkpoint-55000] due to args.save_total_limit\n",
      "/home/shawley/envs/dlaie/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 6327\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to runs/checkpoint-60000\n",
      "Configuration saved in runs/checkpoint-60000/config.json\n",
      "Configuration saved in runs/checkpoint-60000/generation_config.json\n",
      "Model weights saved in runs/checkpoint-60000/pytorch_model.bin\n",
      "Deleting older checkpoint [runs/checkpoint-56000] due to args.save_total_limit\n",
      "/home/shawley/envs/dlaie/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 6327\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to runs/checkpoint-61000\n",
      "Configuration saved in runs/checkpoint-61000/config.json\n",
      "Configuration saved in runs/checkpoint-61000/generation_config.json\n",
      "Model weights saved in runs/checkpoint-61000/pytorch_model.bin\n",
      "Deleting older checkpoint [runs/checkpoint-57000] due to args.save_total_limit\n",
      "/home/shawley/envs/dlaie/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 6327\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to runs/checkpoint-62000\n",
      "Configuration saved in runs/checkpoint-62000/config.json\n",
      "Configuration saved in runs/checkpoint-62000/generation_config.json\n",
      "Model weights saved in runs/checkpoint-62000/pytorch_model.bin\n",
      "Deleting older checkpoint [runs/checkpoint-58000] due to args.save_total_limit\n",
      "/home/shawley/envs/dlaie/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 6327\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to runs/checkpoint-66000\n",
      "Configuration saved in runs/checkpoint-66000/config.json\n",
      "Configuration saved in runs/checkpoint-66000/generation_config.json\n",
      "Model weights saved in runs/checkpoint-66000/pytorch_model.bin\n",
      "Deleting older checkpoint [runs/checkpoint-62000] due to args.save_total_limit\n",
      "/home/shawley/envs/dlaie/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 6327\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to runs/checkpoint-67000\n",
      "Configuration saved in runs/checkpoint-67000/config.json\n",
      "Configuration saved in runs/checkpoint-67000/generation_config.json\n",
      "Model weights saved in runs/checkpoint-67000/pytorch_model.bin\n",
      "Deleting older checkpoint [runs/checkpoint-63000] due to args.save_total_limit\n",
      "/home/shawley/envs/dlaie/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 6327\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to runs/checkpoint-68000\n",
      "Configuration saved in runs/checkpoint-68000/config.json\n",
      "Configuration saved in runs/checkpoint-68000/generation_config.json\n",
      "Model weights saved in runs/checkpoint-68000/pytorch_model.bin\n",
      "Deleting older checkpoint [runs/checkpoint-64000] due to args.save_total_limit\n",
      "/home/shawley/envs/dlaie/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 6327\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to runs/checkpoint-69000\n",
      "Configuration saved in runs/checkpoint-69000/config.json\n",
      "Configuration saved in runs/checkpoint-69000/generation_config.json\n",
      "Model weights saved in runs/checkpoint-69000/pytorch_model.bin\n",
      "Deleting older checkpoint [runs/checkpoint-65000] due to args.save_total_limit\n",
      "/home/shawley/envs/dlaie/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 6327\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to runs/checkpoint-70000\n",
      "Configuration saved in runs/checkpoint-70000/config.json\n",
      "Configuration saved in runs/checkpoint-70000/generation_config.json\n",
      "Model weights saved in runs/checkpoint-70000/pytorch_model.bin\n",
      "Deleting older checkpoint [runs/checkpoint-66000] due to args.save_total_limit\n",
      "/home/shawley/envs/dlaie/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 6327\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to runs/checkpoint-71000\n",
      "Configuration saved in runs/checkpoint-71000/config.json\n",
      "Configuration saved in runs/checkpoint-71000/generation_config.json\n",
      "Model weights saved in runs/checkpoint-71000/pytorch_model.bin\n",
      "Deleting older checkpoint [runs/checkpoint-67000] due to args.save_total_limit\n",
      "/home/shawley/envs/dlaie/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 6327\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to runs/checkpoint-72000\n",
      "Configuration saved in runs/checkpoint-72000/config.json\n",
      "Configuration saved in runs/checkpoint-72000/generation_config.json\n",
      "Model weights saved in runs/checkpoint-72000/pytorch_model.bin\n",
      "Deleting older checkpoint [runs/checkpoint-68000] due to args.save_total_limit\n",
      "/home/shawley/envs/dlaie/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 6327\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to runs/checkpoint-73000\n",
      "Configuration saved in runs/checkpoint-73000/config.json\n",
      "Configuration saved in runs/checkpoint-73000/generation_config.json\n",
      "Model weights saved in runs/checkpoint-73000/pytorch_model.bin\n",
      "Deleting older checkpoint [runs/checkpoint-69000] due to args.save_total_limit\n",
      "/home/shawley/envs/dlaie/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 6327\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to runs/checkpoint-74000\n",
      "Configuration saved in runs/checkpoint-74000/config.json\n",
      "Configuration saved in runs/checkpoint-74000/generation_config.json\n",
      "Model weights saved in runs/checkpoint-74000/pytorch_model.bin\n",
      "Deleting older checkpoint [runs/checkpoint-70000] due to args.save_total_limit\n",
      "/home/shawley/envs/dlaie/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 6327\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to runs/checkpoint-75000\n",
      "Configuration saved in runs/checkpoint-75000/config.json\n",
      "Configuration saved in runs/checkpoint-75000/generation_config.json\n",
      "Model weights saved in runs/checkpoint-75000/pytorch_model.bin\n",
      "Deleting older checkpoint [runs/checkpoint-71000] due to args.save_total_limit\n",
      "/home/shawley/envs/dlaie/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 6327\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to runs/checkpoint-76000\n",
      "Configuration saved in runs/checkpoint-76000/config.json\n",
      "Configuration saved in runs/checkpoint-76000/generation_config.json\n",
      "Model weights saved in runs/checkpoint-76000/pytorch_model.bin\n",
      "Deleting older checkpoint [runs/checkpoint-72000] due to args.save_total_limit\n",
      "/home/shawley/envs/dlaie/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 6327\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to runs/checkpoint-77000\n",
      "Configuration saved in runs/checkpoint-77000/config.json\n",
      "Configuration saved in runs/checkpoint-77000/generation_config.json\n",
      "Model weights saved in runs/checkpoint-77000/pytorch_model.bin\n",
      "Deleting older checkpoint [runs/checkpoint-73000] due to args.save_total_limit\n",
      "/home/shawley/envs/dlaie/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 6327\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to runs/checkpoint-78000\n",
      "Configuration saved in runs/checkpoint-78000/config.json\n",
      "Configuration saved in runs/checkpoint-78000/generation_config.json\n",
      "Model weights saved in runs/checkpoint-78000/pytorch_model.bin\n",
      "Deleting older checkpoint [runs/checkpoint-74000] due to args.save_total_limit\n",
      "/home/shawley/envs/dlaie/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 6327\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to runs/checkpoint-79000\n",
      "Configuration saved in runs/checkpoint-79000/config.json\n",
      "Configuration saved in runs/checkpoint-79000/generation_config.json\n",
      "Model weights saved in runs/checkpoint-79000/pytorch_model.bin\n",
      "Deleting older checkpoint [runs/checkpoint-75000] due to args.save_total_limit\n",
      "/home/shawley/envs/dlaie/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 6327\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to runs/checkpoint-80000\n",
      "Configuration saved in runs/checkpoint-80000/config.json\n",
      "Configuration saved in runs/checkpoint-80000/generation_config.json\n",
      "Model weights saved in runs/checkpoint-80000/pytorch_model.bin\n",
      "Deleting older checkpoint [runs/checkpoint-76000] due to args.save_total_limit\n",
      "/home/shawley/envs/dlaie/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 6327\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to runs/checkpoint-81000\n",
      "Configuration saved in runs/checkpoint-81000/config.json\n",
      "Configuration saved in runs/checkpoint-81000/generation_config.json\n",
      "Model weights saved in runs/checkpoint-81000/pytorch_model.bin\n",
      "Deleting older checkpoint [runs/checkpoint-77000] due to args.save_total_limit\n",
      "/home/shawley/envs/dlaie/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 6327\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to runs/checkpoint-82000\n",
      "Configuration saved in runs/checkpoint-82000/config.json\n",
      "Configuration saved in runs/checkpoint-82000/generation_config.json\n",
      "Model weights saved in runs/checkpoint-82000/pytorch_model.bin\n",
      "Deleting older checkpoint [runs/checkpoint-78000] due to args.save_total_limit\n",
      "/home/shawley/envs/dlaie/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 6327\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to runs/checkpoint-83000\n",
      "Configuration saved in runs/checkpoint-83000/config.json\n",
      "Configuration saved in runs/checkpoint-83000/generation_config.json\n",
      "Model weights saved in runs/checkpoint-83000/pytorch_model.bin\n",
      "Deleting older checkpoint [runs/checkpoint-79000] due to args.save_total_limit\n",
      "/home/shawley/envs/dlaie/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 6327\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to runs/checkpoint-84000\n",
      "Configuration saved in runs/checkpoint-84000/config.json\n",
      "Configuration saved in runs/checkpoint-84000/generation_config.json\n",
      "Model weights saved in runs/checkpoint-84000/pytorch_model.bin\n",
      "Deleting older checkpoint [runs/checkpoint-80000] due to args.save_total_limit\n",
      "/home/shawley/envs/dlaie/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 6327\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to runs/checkpoint-85000\n",
      "Configuration saved in runs/checkpoint-85000/config.json\n",
      "Configuration saved in runs/checkpoint-85000/generation_config.json\n",
      "Model weights saved in runs/checkpoint-85000/pytorch_model.bin\n",
      "Deleting older checkpoint [runs/checkpoint-81000] due to args.save_total_limit\n",
      "/home/shawley/envs/dlaie/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 6327\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to runs/checkpoint-86000\n",
      "Configuration saved in runs/checkpoint-86000/config.json\n",
      "Configuration saved in runs/checkpoint-86000/generation_config.json\n",
      "Model weights saved in runs/checkpoint-86000/pytorch_model.bin\n",
      "Deleting older checkpoint [runs/checkpoint-82000] due to args.save_total_limit\n",
      "/home/shawley/envs/dlaie/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 6327\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to runs/checkpoint-87000\n",
      "Configuration saved in runs/checkpoint-87000/config.json\n",
      "Configuration saved in runs/checkpoint-87000/generation_config.json\n",
      "Model weights saved in runs/checkpoint-87000/pytorch_model.bin\n",
      "Deleting older checkpoint [runs/checkpoint-83000] due to args.save_total_limit\n",
      "/home/shawley/envs/dlaie/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 6327\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to runs/checkpoint-88000\n",
      "Configuration saved in runs/checkpoint-88000/config.json\n",
      "Configuration saved in runs/checkpoint-88000/generation_config.json\n",
      "Model weights saved in runs/checkpoint-88000/pytorch_model.bin\n",
      "Deleting older checkpoint [runs/checkpoint-84000] due to args.save_total_limit\n",
      "/home/shawley/envs/dlaie/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 6327\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to runs/checkpoint-89000\n",
      "Configuration saved in runs/checkpoint-89000/config.json\n",
      "Configuration saved in runs/checkpoint-89000/generation_config.json\n",
      "Model weights saved in runs/checkpoint-89000/pytorch_model.bin\n",
      "Deleting older checkpoint [runs/checkpoint-85000] due to args.save_total_limit\n",
      "/home/shawley/envs/dlaie/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 6327\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to runs/checkpoint-90000\n",
      "Configuration saved in runs/checkpoint-90000/config.json\n",
      "Configuration saved in runs/checkpoint-90000/generation_config.json\n",
      "Model weights saved in runs/checkpoint-90000/pytorch_model.bin\n",
      "Deleting older checkpoint [runs/checkpoint-86000] due to args.save_total_limit\n",
      "/home/shawley/envs/dlaie/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 6327\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to runs/checkpoint-91000\n",
      "Configuration saved in runs/checkpoint-91000/config.json\n",
      "Configuration saved in runs/checkpoint-91000/generation_config.json\n",
      "Model weights saved in runs/checkpoint-91000/pytorch_model.bin\n",
      "Deleting older checkpoint [runs/checkpoint-87000] due to args.save_total_limit\n",
      "/home/shawley/envs/dlaie/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 6327\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to runs/checkpoint-92000\n",
      "Configuration saved in runs/checkpoint-92000/config.json\n",
      "Configuration saved in runs/checkpoint-92000/generation_config.json\n",
      "Model weights saved in runs/checkpoint-92000/pytorch_model.bin\n",
      "Deleting older checkpoint [runs/checkpoint-88000] due to args.save_total_limit\n",
      "/home/shawley/envs/dlaie/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 6327\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to runs/checkpoint-93000\n",
      "Configuration saved in runs/checkpoint-93000/config.json\n",
      "Configuration saved in runs/checkpoint-93000/generation_config.json\n",
      "Model weights saved in runs/checkpoint-93000/pytorch_model.bin\n",
      "Deleting older checkpoint [runs/checkpoint-89000] due to args.save_total_limit\n",
      "/home/shawley/envs/dlaie/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 6327\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to runs/checkpoint-94000\n",
      "Configuration saved in runs/checkpoint-94000/config.json\n",
      "Configuration saved in runs/checkpoint-94000/generation_config.json\n",
      "Model weights saved in runs/checkpoint-94000/pytorch_model.bin\n",
      "Deleting older checkpoint [runs/checkpoint-90000] due to args.save_total_limit\n",
      "/home/shawley/envs/dlaie/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 6327\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to runs/checkpoint-95000\n",
      "Configuration saved in runs/checkpoint-95000/config.json\n",
      "Configuration saved in runs/checkpoint-95000/generation_config.json\n",
      "Model weights saved in runs/checkpoint-95000/pytorch_model.bin\n",
      "Deleting older checkpoint [runs/checkpoint-91000] due to args.save_total_limit\n",
      "/home/shawley/envs/dlaie/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 6327\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to runs/checkpoint-96000\n",
      "Configuration saved in runs/checkpoint-96000/config.json\n",
      "Configuration saved in runs/checkpoint-96000/generation_config.json\n",
      "Model weights saved in runs/checkpoint-96000/pytorch_model.bin\n",
      "Deleting older checkpoint [runs/checkpoint-92000] due to args.save_total_limit\n",
      "/home/shawley/envs/dlaie/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 6327\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to runs/checkpoint-97000\n",
      "Configuration saved in runs/checkpoint-97000/config.json\n",
      "Configuration saved in runs/checkpoint-97000/generation_config.json\n",
      "Model weights saved in runs/checkpoint-97000/pytorch_model.bin\n",
      "Deleting older checkpoint [runs/checkpoint-93000] due to args.save_total_limit\n",
      "/home/shawley/envs/dlaie/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 6327\n",
      "  Batch size = 48\n",
      "Saving model checkpoint to runs/checkpoint-100000\n",
      "Configuration saved in runs/checkpoint-100000/config.json\n",
      "Configuration saved in runs/checkpoint-100000/generation_config.json\n",
      "Model weights saved in runs/checkpoint-100000/pytorch_model.bin\n",
      "Deleting older checkpoint [runs/checkpoint-96000] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from runs/checkpoint-27000 (score: 3.793501615524292).\n",
      "There were missing keys in the checkpoint model loaded: ['lm_head.weight'].\n",
      "Saving model checkpoint to runs\n",
      "Configuration saved in runs/config.json\n",
      "Configuration saved in runs/generation_config.json\n",
      "Model weights saved in runs/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** train metrics *****\n",
      "  epoch                    =      325.03\n",
      "  total_flos               = 347627597GF\n",
      "  train_loss               =      2.8814\n",
      "  train_runtime            = 21:22:36.00\n",
      "  train_samples_per_second =      62.373\n",
      "  train_steps_per_second   =       1.299\n"
     ]
    }
   ],
   "source": [
    "metrics = {metric: load_metric(metric) for metric in [\"accuracy\"]}\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    \"\"\"Computes metrics for pretraining.\n",
    "    Must use proprocess_logits function that converts logits to predictions (argmax or sampling).\n",
    "\n",
    "    :param eval_pred: EvalPrediction containing predictions and labels\n",
    "    :return: metrics\n",
    "    \"\"\"\n",
    "    predictions, labels = eval_pred\n",
    "    not_pad_mask = labels != -100\n",
    "    labels, predictions = labels[not_pad_mask], predictions[not_pad_mask]\n",
    "    return metrics[\"accuracy\"].compute(predictions=predictions.flatten(), references=labels.flatten())\n",
    "\n",
    "def preprocess_logits(logits: Tensor, _: Tensor) -> Tensor:\n",
    "    \"\"\"Preprocesses the logits before accumulating them during evaluation.\n",
    "    This allows to significantly reduce the memory usage and make the training tractable.\n",
    "    \"\"\"\n",
    "    pred_ids = argmax(logits, dim=-1)  # long dtype\n",
    "    return pred_ids\n",
    "\n",
    "# Create config for the Trainer\n",
    "USE_CUDA = cuda_available()\n",
    "if not cuda_available():\n",
    "    FP16 = FP16_EVAL = BF16 = BF16_EVAL = False\n",
    "elif is_bf16_supported():\n",
    "    BF16 = BF16_EVAL = True\n",
    "    FP16 = FP16_EVAL = False\n",
    "else:\n",
    "    BF16 = BF16_EVAL = False\n",
    "    FP16 = FP16_EVAL = True\n",
    "USE_MPS = not USE_CUDA and mps_available()\n",
    "training_config = TrainingArguments(\n",
    "    \"runs\", False, True, True, False, \"steps\",\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=48,\n",
    "    gradient_accumulation_steps=3,\n",
    "    eval_accumulation_steps=None,\n",
    "    eval_steps=1000,\n",
    "    learning_rate=1e-4,\n",
    "    weight_decay=0.01,\n",
    "    max_grad_norm=3.0,\n",
    "    max_steps=100000,\n",
    "    lr_scheduler_type=\"cosine_with_restarts\",\n",
    "    warmup_ratio=0.3,\n",
    "    log_level=\"debug\",\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=20,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=1000,\n",
    "    save_total_limit=5,\n",
    "    no_cuda=not USE_CUDA,\n",
    "    seed=444,\n",
    "    fp16=FP16,\n",
    "    fp16_full_eval=FP16_EVAL,\n",
    "    bf16=BF16,\n",
    "    bf16_full_eval=BF16_EVAL,\n",
    "    load_best_model_at_end=True,\n",
    "    label_smoothing_factor=0.,\n",
    "    optim=\"adamw_torch\",\n",
    "    report_to=[\"tensorboard\"],\n",
    "    gradient_checkpointing=True,\n",
    ")\n",
    "\n",
    "collator = DataCollator(tokenizer[\"PAD_None\"], tokenizer[\"BOS_None\"], tokenizer[\"EOS_None\"], copy_inputs_as_labels=True)\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_config,\n",
    "    data_collator=collator,\n",
    "    train_dataset=subset_train,\n",
    "    eval_dataset=subset_valid,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=None,\n",
    "    preprocess_logits_for_metrics=preprocess_logits,\n",
    ")\n",
    "\n",
    "# Training\n",
    "train_result = trainer.train()\n",
    "trainer.save_model()  # Saves the tokenizer too\n",
    "trainer.log_metrics(\"train\", train_result.metrics)\n",
    "trainer.save_metrics(\"train\", train_result.metrics)\n",
    "trainer.save_state()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate music"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "cellView": "form",
    "id": "OaNkGcFo9UP_"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing model / Generating results: 100%|██████████| 396/396 [03:36<00:00,  1.83it/s]\n"
     ]
    }
   ],
   "source": [
    "(gen_results_path := Path('gen_res')).mkdir(parents=True, exist_ok=True)\n",
    "generation_config = GenerationConfig(\n",
    "    max_new_tokens=768, #512,  # extends samples by 512 tokens\n",
    "    num_beams=1,        # no beam search\n",
    "    do_sample=True,     # but sample instead\n",
    "    temperature=0.9,\n",
    "    top_k=15,\n",
    "    top_p=0.95,\n",
    "    epsilon_cutoff=3e-4,\n",
    "    eta_cutoff=1e-3,\n",
    "    pad_token_id=config.padding_token_id,\n",
    ")\n",
    "\n",
    "# Here the sequences are padded to the left, so that the last token along the time dimension\n",
    "# is always the last token of each seq, allowing to efficiently generate by batch\n",
    "collator.pad_on_left = True\n",
    "collator.eos_token = None\n",
    "dataloader_test = DataLoader(subset_valid, batch_size=16, collate_fn=collator)\n",
    "model.eval()\n",
    "count = 0\n",
    "for batch in tqdm(dataloader_test, desc='Testing model / Generating results'):  # (N,T)\n",
    "    res = model.generate(\n",
    "        inputs=batch[\"input_ids\"].to(model.device),\n",
    "        attention_mask=batch[\"attention_mask\"].to(model.device),\n",
    "        generation_config=generation_config)  # (N,T)\n",
    "\n",
    "    # Saves the generated music, as MIDI files and tokens (json)\n",
    "    for prompt, continuation in zip(batch[\"input_ids\"], res):\n",
    "        generated = continuation[len(prompt):]\n",
    "        midi = tokenizer.tokens_to_midi([deepcopy(generated.tolist())], time_division=384)\n",
    "        tokens = [generated, prompt, continuation]  # list compr. as seqs of dif. lengths\n",
    "        tokens = [seq.tolist() for seq in tokens]\n",
    "        for tok_seq in tokens[1:]:\n",
    "            _midi = tokenizer.tokens_to_midi([deepcopy(tok_seq)], time_division=384)\n",
    "            midi.instruments.append(_midi.instruments[0])\n",
    "        midi.instruments[0].name = f'Continuation of original sample ({len(generated)} tokens)'\n",
    "        midi.instruments[1].name = f'Original sample ({len(prompt)} tokens)'\n",
    "        midi.instruments[2].name = f'Original sample and continuation'\n",
    "        midi.dump(gen_results_path / f'{count}.mid')\n",
    "        tokenizer.save_tokens(tokens, gen_results_path / f'{count}.json') \n",
    "\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Optimus_VIRTUOSO_Multi_Instrumental_RGA_Edition.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
